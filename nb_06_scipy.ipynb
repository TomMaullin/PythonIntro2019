{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 6: SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will introduce you to the `scipy` (\"Scientific Python\") package; a package built on top of `numpy` which contains many miscellaneous but useful functions. Unlike `numpy` you may find that you do not use `scipy` frequently. However, you may often find that using `scipy` functions may help improve your code and save you time in the long run! \n",
    "\n",
    "This notebook will give a brief description of some of the things you can do with `scipy` and highlights why `scipy` may be useful to you in the future!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great strengths of `scipy` is it's statistics library. From the [documentation homepage](https://docs.scipy.org/doc/scipy/reference/stats.html), it can be seen that there are over 100 functions provided by `scipy` for generating various random variables and performing a multitude of hypothesis tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in the below code a one-sample two-tailed [T-test](https://en.wikipedia.org/wiki/Student%27s_t-test) is performed. This takes two samples and tests whether they have been drawn from distributions which possess the same mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two random samples from a Normal distribution\n",
    "sample1 = np.random.normal(size=100)\n",
    "sample2 = np.random.normal(size=100)\n",
    "\n",
    "# Perform a T test\n",
    "res = stats.ttest_ind(sample1, sample2)\n",
    "\n",
    "# Print the result\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** If you are not familiar with statistical hypothesis testing it is definitely recommended that you read up on this - it is a certainty you will come across tests of this form again if you work with statstics! Please ask one of us if you need help getting started with this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code performs the same test but this time using data drawn from two different distributions. See if you get a statistically significant result when you run the code. If not what does this tell you? Be careful with your answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two random samples from two different Normal distributions\n",
    "sample1 = np.random.normal(loc=0.2,size=100)\n",
    "sample2 = np.random.normal(scale=0.9,size=100)\n",
    "\n",
    "# Perform a T test\n",
    "res = stats.ttest_ind(sample1, sample2)\n",
    "\n",
    "# Print the result\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just one example of many useful statistical functions in the `scipy` package. Have a look at the [documentation](https://docs.scipy.org/doc/scipy/reference/stats.html) to see what else you can do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy` also includes many of the linear algebra functions given in `numpy` and more! The `scipy` linear algebra functions can come in very handy but are often tailored to specific applicatons. Whilst you are likely to regularly use one or two functions from this module in practice, it is unlikely you will use more than that. For this reason we will only give a few examples from the `scipy` linear algebra package! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example you may find yourself using quite often is given by the `block_diag` function; which can be used for constructing block diagonal matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's construct some matrices\n",
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.array([[5,6,7],[8,9,10],[11,12,13]])\n",
    "c = np.array([[14,15],[16,17]])\n",
    "\n",
    "# Let's have a quick look at our matrices\n",
    "print('a:')\n",
    "print(a)\n",
    "print('b:')\n",
    "print(b)\n",
    "print('c:')\n",
    "print(c)\n",
    "\n",
    "# Now lets combine them as one large block diagonal matrix!\n",
    "d = linalg.block_diag(a,b,c)\n",
    "\n",
    "# Let's have a look at d\n",
    "print('---------------------------')\n",
    "print('d:')\n",
    "print(d)\n",
    "\n",
    "# Try changing the order of a,b and c in the `block_diag` function - how does d change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy` also allows you to easily create a range of other matrices exhibiting special structures such as [Toeplitz](https://en.wikipedia.org/wiki/Toeplitz_matrix) and [Circulant](https://en.wikipedia.org/wiki/Circulant_matrix) matrices. These are matrices which you may find yourself using quite a lot if you end up working with Fourier analyses or autoregressive models. See if you can work out what Toeplitz and Circulant matrices are using the below code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a Toeplitz matrix we need to specify the first row and column\n",
    "row = np.array([1,2,3,6])\n",
    "col = np.array([1,8,9,7,10])\n",
    "\n",
    "# Lets make the Toeplitz matrix!\n",
    "toep = linalg.toeplitz(col,row)\n",
    "\n",
    "# Lets print the Toeplitz matrix!\n",
    "print(toep)\n",
    "\n",
    "# To create a Circulant matrix we only need a row!\n",
    "circ = linalg.circulant(row)\n",
    "\n",
    "# Lets print the circulant matrix!\n",
    "print(circ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most useful functions in the `scipy` linalg package is the permuted [LU decomposition](https://en.wikipedia.org/wiki/LU_decomposition) (which is currently not supported in `numpy`). The LU decomposition has a wide range of applications in statistics and can be performed as shown below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "\n",
    "# Make a random matrix with numpy\n",
    "x = np.random.randn(3,3)\n",
    "print(x)\n",
    "print('----------------------')\n",
    "\n",
    "# Get the lu decomposition\n",
    "P, L, U = linalg.lu(x, permute_l=False)\n",
    "\n",
    "# P should be a permutation\n",
    "print(P)\n",
    "# L should be lower triangular\n",
    "print(L)\n",
    "# U should be upper triangular\n",
    "print(U)\n",
    "print('----------------------')\n",
    "\n",
    "# The product of PLU should be our original matrix\n",
    "print(P @ L @ U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful feature in `scipy` is the interpolation module which can be used to interpolate data. To interpolate 1-dimensional data, we can use the `interp1d` function. To see how this works, let's first make some data for our example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import interpolation\n",
    "from scipy import interpolate\n",
    "\n",
    "# Make some data\n",
    "x = np.linspace(0, 5, num=11, endpoint=True)\n",
    "y = np.cos(-x**3/9.0)\n",
    "\n",
    "\n",
    "# Make a plot showing the data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, y, 'o')\n",
    "plt.legend(['data'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is our data! Below, we use `scipy` to perform [Nearest Neighbour](https://en.wikipedia.org/wiki/Nearest_neighbour_algorithm) interpolation. If you aren't familiar with Nearest Neighbour interpolation, don't worry; see if you can guess what is happening based on the below figure!\n",
    "\n",
    "> **Note:** We haven't discussed creating plots yet. Don't worry if the above code seems very unfamiliar; The `matplotlib` package which is used for making plots will be covered in more detail in Notebook 7!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interp1d will give us a special function we can use to\n",
    "# interpolate our data!\n",
    "interpolated = interpolate.interp1d(x, y, kind='nearest')\n",
    "\n",
    "# Lets make a new range of x values which we wish to \n",
    "# interpolate our data on!\n",
    "x_interpolate = np.linspace(0, 5, num=1001, endpoint=True)\n",
    "\n",
    "# Lets get our new interpolated values\n",
    "y_interpolate = interpolated(x_interpolate)\n",
    "\n",
    "# Plot the original data\n",
    "plt.plot(x, y, 'o')\n",
    "\n",
    "# Plot the interpolated data\n",
    "plt.plot(x_interpolate, y_interpolate, '--')\n",
    "\n",
    "# Add a key\n",
    "plt.legend(['data', 'interpolated'], loc='best')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead let's try linear interpolation! What has changed in the below code? Which interpolation do you think seems most appropriate for this dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interp1d will give us a special function we can use to\n",
    "# interpolate our data!\n",
    "interpolated = interpolate.interp1d(x, y, kind='linear')\n",
    "\n",
    "# Lets make a new range of x values which we wish to \n",
    "# interpolate our data on!\n",
    "x_interpolate = np.linspace(0, 5, num=1001, endpoint=True)\n",
    "\n",
    "# Lets get our new interpolated values\n",
    "y_interpolate = interpolated(x_interpolate)\n",
    "\n",
    "# Plot the original data\n",
    "plt.plot(x, y, 'o')\n",
    "\n",
    "# Plot the interpolated data\n",
    "plt.plot(x_interpolate, y_interpolate, '--')\n",
    "\n",
    "# Add a key\n",
    "plt.legend(['data', 'interpolated'], loc='best')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's try cubic interpolation! Which of the 3 interpolation methods do you think was most useful and why (be careful with your answer!)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interp1d will give us a special function we can use to\n",
    "# interpolate our data!\n",
    "interpolated = interpolate.interp1d(x, y, kind='cubic')\n",
    "\n",
    "# Lets make a new range of x values which we wish to \n",
    "# interpolate our data on!\n",
    "x_interpolate = np.linspace(0, 5, num=1001, endpoint=True)\n",
    "\n",
    "# Lets get our new interpolated values\n",
    "y_interpolate = interpolated(x_interpolate)\n",
    "\n",
    "# Plot the original data\n",
    "plt.plot(x, y, 'o')\n",
    "\n",
    "# Plot the interpolated data\n",
    "plt.plot(x_interpolate, y_interpolate, '--')\n",
    "\n",
    "# Add a key\n",
    "plt.legend(['data', 'interpolated'], loc='best')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions similar to `interp1d` also exist for [2-dimensional](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp2d.html#scipy.interpolate.interp2d) and [n-dimensional](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interpn.html#scipy.interpolate.interpn) datasets and even more options for other interpolation methods, such as splines and B-splines, exist as well. This notebook is only intended to give a brief overview of what is possible with scipy but note that many more options are available for performing interpolation (see the [documentation here](https://docs.scipy.org/doc/scipy/reference/interpolate.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy` includes support for the `sparse` matrix format (a faster way of working with matrices with few non-zero elements, which works by only storing and using the non-zero elements in computation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On very sparse examples, the `scipy` sparse functions can be much faster than `numpy`. To demonstrate this let's create a very large sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a random matrix and keep only a few elements\n",
    "X = np.random.randn(1000,1000)\n",
    "X[X<2.5] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As `X` is very large, we cannot look at it by printing it in the commandline. The below code shows us what `X` looks like pictorially. In this image, the non-zero elements of `X` are represented by the light \"specks\" while the dark blue background represents where `X` contains zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an image of the matrix\n",
    "plt.imshow(X, interpolation='nearest', aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, `X` is very large and very sparse. Let's now represent `X` with a `scipy` sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a sparse version of X using scipy\n",
    "X_sparse = sparse.csr_matrix(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate why it may be useful to use `scipy` here, let's calculate the transpose of `X` multiplied by `X` using both `numpy` and `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Lets work out X transpose multiplied by X \n",
    "# using the original dense (numpy) matrix\n",
    "t1 = time.time()\n",
    "XtX = X.T @ X\n",
    "t2 = time.time()\n",
    "print(\"Using dense (numpy) matrices the calculation X @ X.T took:\")\n",
    "print(t2-t1, \"seconds\")\n",
    "\n",
    "# Lets work out X transpose multiplied by X \n",
    "# using the sparse (scipy) matrix\n",
    "t1 = time.time()\n",
    "XtX = X_sparse.T @ X_sparse\n",
    "t2 = time.time()\n",
    "print(\"Using sparse (scipy) matrices the calculation X @ X.T took:\")\n",
    "print(t2-t1, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example `scipy` was much faster! In general, it is recommended that if you are working with sparse data you should employ sparse matrix datatypes. However, `scipy` is not the only option you have for doing this! It is worth noting that [`cvxopt`](https://cvxopt.org/) and [`sparse`](https://pypi.org/project/sparse/) (not to be confused with `scipy.sparse`!) also provide great tools that may be of some use to you in the future if you ever need to work with sparse matrices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common application for sparse matrices is network analysis. `scipy.sparse` also has a useful module for network analysis. Typically, in network analysis, graphs are represented by [adjaceny matrices](https://en.wikipedia.org/wiki/Adjacency_matrix). For example, the below graph:\n",
    "\n",
    "![graph](06_scipy/graph.png)\n",
    "\n",
    "can be represented by this (sparse) adjacency matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = sparse.csr_matrix(np.array([[1,1,0,3,0,0],\n",
    "                                  [1,0,0,1,0,0],\n",
    "                                  [0,0,0,0,1,0],\n",
    "                                  [3,1,0,0,0,1],\n",
    "                                  [0,0,1,0,0,0],\n",
    "                                  [0,0,0,1,0,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `scipy.sparse` to learn a lot about this graph. For example, we can get the connected components in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sparse.csgraph.connected_components(adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that nodes $0,1,3$ and $5$ in the graph form one connected component (labelled `0`) and the nodes $2$ and $4$ in the graph form another connected component (labelled `1`). \n",
    "\n",
    "We can also use the `scipy.sparse` package to perform Dijkstra's algorithm to find the shortest path between nodes. For example, the below shows the shortest path to each node when starting from node $5$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sparse.csgraph.dijkstra(adj, indices=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often in statistics, you will find that you need to find local or global minima or maxima of functions. The most common example of this is probably [Maximum Likelihood Estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) which you may have come across recently in the statistics introduction classes. \n",
    "\n",
    "As you may frequently find, often nice formulae for global maxima and minima of functions aren't available in practice. `scipy` has an invaluable module for numerically solving problems of this kind - the `optimize` package!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate how this module can be used, let's consider a simple example where we know the answer. Consider a polynomial of the form:\n",
    "$$f(x)=ax^2+bx+c$$\n",
    "\n",
    "where $a>0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates a quadratic equation in x\n",
    "def quadratic(x,a,b,c):\n",
    "    \n",
    "    return(a*x**2+b*x+c)\n",
    "\n",
    "# Lets just quickly test a few values\n",
    "a=1\n",
    "b=4\n",
    "c=4\n",
    "x=8\n",
    "\n",
    "print('The value of '+str(a)+'*'+str(x)+'^2+'+str(b)+'*'+str(x)+'+'+str(c)+' is:')\n",
    "print(quadratic(x,a,b,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the value of $x$ which minimizes $f(x)$ using the `minimize` function from `scipy.optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the minimum of the function\n",
    "result=optimize.minimize(quadratic, x0=1, args=(a,b,c), method='Nelder-Mead')\n",
    "\n",
    "print('The minimum of '+str(a)+'x^2+'+str(b)+'x+'+str(c)+' is: ', result.x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking this answer using some basic algebra should show it to be correct! Have a look at the documentation for [`scipy.optimize`](https://docs.scipy.org/doc/scipy/reference/optimize.html). See if you can answer the following questions:\n",
    "\n",
    " - What are the arguments in the above expression? \n",
    " - Try changing `x0` to `1000`. Is the answer the same? Why/why not? \n",
    " - Note that we have opted here to use the \"Nelder-Mead\" method; what other methods are available? What may influence your choice of optimization method?\n",
    " - What else is included in the `result` output variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often in statistics you will also have evaluate integrals which don't have nice analytic expressions. Luckily, `scipy` can do this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a demonstration, let's integrate our quadratic function from earlier between $0$ and $2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to integrate our quadratic function between 0 and 2\n",
    "lower = 0\n",
    "upper = 2\n",
    "\n",
    "result = integrate.quad(lambda x: quadratic(x,a,b,c), lower, upper)\n",
    "\n",
    "print('The integral of '+str(a)+'x^2+'+str(b)+'x+'+str(c)+' between ' + str(lower) + ' and '+ str(upper) + ' is: ')\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this answer agree with what you would expect? Look online to see if you can work out how the `lambda` expression works in the above code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy` has a wide range of useful and interesting functions for working on numeric data. This notebook has barely scratched the surface in terms of listing `scipy` features. A, by no means complete, list of `scipy` capabilities include:\n",
    "\n",
    " - Integration (`scipy.integrate`)\n",
    " - Optimization (`scipy.optimize`)\n",
    " - Fourier Transforms (`scipy.fftpack`)\n",
    " - Signal Processing (`scipy.signal`)\n",
    " - Spatial data structures and algorithms (`scipy.spatial`)\n",
    " - Statistics and random numbers (`scipy.stats`)\n",
    " - Multidimensional image processing (`scipy.ndimage`)\n",
    " - File handling (`scipy.io`)\n",
    " - Other special functions (`scipy.special`)\n",
    " \n",
    "And much, much more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** In the `More linear algebra` section of this notebook we saw how the `block_diag` function works. Although `numpy` does not have a direct function for constructing block diagonal matrices, you can still construct block diagonal matrices using a combination of other `numpy` functions. \n",
    "\n",
    "Using `numpy` or otherwise, write your own function for constructing a block diagonal matrix from 3 seperate matrices. Test your function against `scipy` to see if it behaves correctly.\n",
    "\n",
    "**Bonus:** Using the `time` module time your code to see how it performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some random arbitrary matrices\n",
    "A = np.random.randn(2,3)\n",
    "B = np.random.randn(4,3)\n",
    "C = np.random.randn(3,6)\n",
    "\n",
    "# This should return a block diagonal matrix with A,B,C on\n",
    "# the diagonals\n",
    "def my_block_diag(A,B,C):\n",
    "    \n",
    "    # Write your function here.\n",
    "    \n",
    "# This is what you expect to get\n",
    "D_expected = linalg.block_diag(A,B,C)\n",
    "\n",
    "# This is what your function gives\n",
    "D_test = my_block_diag(A,B,C)\n",
    "\n",
    "# Let's see if their equal!\n",
    "print('Did my function work: ', np.allclose(D_expected,D_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Below are four samples generated by four functions. Each function generates a sample from a different \"mystery\" distribution. One or more of the functions is generating data according to a standard normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the mystery functions!\n",
    "import os\n",
    "os.chdir('06_scipy')\n",
    "\n",
    "from mystDist import *\n",
    "\n",
    "# number of samples\n",
    "n = 1000\n",
    "\n",
    "# Generate mystery samples\n",
    "sample1 = mysteryDistribution1(n)\n",
    "sample2 = mysteryDistribution2(n)\n",
    "sample3 = mysteryDistribution3(n)\n",
    "sample4 = mysteryDistribution4(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify an appropriate statistical testing procedure provided by the `scipy` package which may help you assess which of the samples follows a standard normal distribution. Perform your test below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your testing procedure here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you conclude from your tests? Be **very** [careful](https://en.wikipedia.org/wiki/Misuse_of_p-values) on how you phrase your answer here.\n",
    "\n",
    "Does your testing procedure produce valid results? (You may wish to look at this [wiki page](https://en.wikipedia.org/wiki/Multiple_comparisons_problem) before answering!)\n",
    "\n",
    "If the test doesn't provide conclusive results should you change testing strategy? (Be **very** [wary](https://en.wikipedia.org/wiki/Data_dredging) here as well)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** The [error function](https://en.wikipedia.org/wiki/Error_function), `erf`, is a function which occurs quite a lot in statistics, as it is the probability of a random variable, with normal distribution of mean $0$ and variance $\\frac{1}{2}$ falling in the range $[-x,x]$. Unfortunately, the \"simplest\" expression for the `erf` involves an integral expression;\n",
    "\n",
    "$$\\text{erf}(x)=\\frac{2}{\\sqrt\\pi}\\int_{0}^xe^{-\\frac{y^2}{2}}dy$$\n",
    "\n",
    "Using the `scipy` `integrate` module, write your own function which calculates the `erf` function. Compare your function against the `scipy` [`erf`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.erf.html#scipy.special.erf) function to see how it performs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the erf as a function of x\n",
    "def my_erf(x):\n",
    "    \n",
    "    # Write your function here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** In this question, $f$ is a function which is given by:\n",
    "\n",
    "$$f(x,y)=\\exp (\\sin (50x))+\\sin (60e^y)+\\sin (70\\sin(x))+\\sin (\\sin (80y))-\\sin (10(x+y))+\\frac{1}{4}(x^2+y^2)$$\n",
    "\n",
    "First, write a function which given a numpy array `xy` equal to $[x,y]$ returns $f(x,y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function must return the value of f(x,y)\n",
    "def my_f(xy):\n",
    "    \n",
    "    # Write your function here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using your function and the `scipy` `optimize` module find the global minima of the function $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a few different minimization methods and starting points. Do you always find the correct local minima? How might you explain the performance of your code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5 (hard):** In this question, the function $g$ is defined by:\n",
    "\n",
    "$$g(\\alpha)=\\int_{0}^2[2+\\sin(10\\alpha)]x^\\alpha\\sin\\bigg(\\frac{\\alpha}{2-x}\\bigg)dx$$\n",
    "\n",
    "By writing an appropriate function and using the `scipy` `integrate` module, try writing a function which takes in a value $\\alpha$ and returns $g(\\alpha)$. Try a few different types of [integral methods](https://docs.scipy.org/doc/scipy/reference/integrate.html). You may find that it isn't possible to get a good result - Why do you think this is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function must return the value of f(x,y)\n",
    "def my_g(alpha):\n",
    "    \n",
    "    # Write your function here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your function from above and the `scipy` `optimize` module, find the value of $\\alpha$ in $[0,5]$ at which $g(\\alpha)$ is largest in value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the $\\alpha$ which gives a minimal value is not as straightforward as it first appears. Why do you think `scipy` might not be the best tool for this problem? Is there a mathematical reason why might we expect that we can't use standard numerical approximation for the integral? Can your results be trusted?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
