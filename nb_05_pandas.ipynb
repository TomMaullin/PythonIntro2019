{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5: Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will look at the package `pandas`. `pandas` is built on top of `numpy` (see Notebook 4 for more on `numpy`) and specializes in dealing with heterogenous and/or missing data often stored in a labelled format. \n",
    "\n",
    "As this is an introductory course we will only give a brief introduction to `pandas` and a flavour of why it may be useful to you. For more information see the [`pandas` documentation here](https://pandas.pydata.org/pandas-docs/stable/).\n",
    "\n",
    "The strength of `pandas` lies in it's ability to handle database and spreadsheet type operations that may be more familiar to users of languages such as `R` and `SQL`. \n",
    "\n",
    " > **Note:** By convention, `pandas` is often aliased as `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas dataypes\n",
    "\n",
    "The world of `pandas` revolves predominantly around the `Series` and `DataFrame` datatypes. We shall look at each one of these in turn now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas `Series`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `pandas` `Series` object is an indexed one-dimensional array of data.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_series = pd.Series([2.1,3.9,4.2])\n",
    "print(example_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert a `pandas` `Series` to a `numpy` `array` very easily using the `values` attribute and we can access the elements of a `Series` using square brackets in the same way we would a one-dimensional `numpy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_series.values)\n",
    "print(example_series[0])\n",
    "print(example_series[0:2])\n",
    "print(example_series[example_series>3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, with a `pandas` `Series` we can change how we index the data. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_series = pd.Series([2.1,3.9,4.2],\n",
    "                           index=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access the data using our both own indices, much like with a Python `dict`, and numerical indices, like a Python `list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_series['b'])\n",
    "print(example_series[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, we can even use `numpy` style array indexing syntax but on our own labels.\n",
    "\n",
    " > **Note**: This indexing, unlike `numpy`, is inclusive. For example, `'a':'b'` includes element `'b'`, unlike in `numpy` where `0:2` does not include element `2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_series['a':'b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Note:** If we use a number as an index for a column; our indices take precedence over the inbuilt `numpy` like indexing. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_series = pd.Series([2.1,3.9,4.2],\n",
    "                           index=[2, 'b', 'c'])\n",
    "print(example_series[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can construct a `pandas` `Series` object from a `dict` like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dict = {'a': 1, 'b': 33, 'c': 2}\n",
    "print(example_dict)\n",
    "print(pd.Series(example_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Note:** If we use the `index` keyword when creating a `series` object from a `dict` only the object with a key in our `index` list will be retained. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dict = {'a': 1, 'b': 33, 'c': 2}\n",
    "print(example_dict)\n",
    "print(pd.Series(example_dict, index=['a','c']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas `Dataframes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `pandas` `DataFrame` object can be thought of as a collection of aligned `pandas` `Series` objects, where by aligned we mean sharing the same index. We can construct a `DataFrame` from several `Series` using the `pandas.DataFrame` object. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series of heights in inches\n",
    "heights = pd.Series({'Pete': 69, 'Mo': 72, 'Katy': 64, 'Alex': 80})\n",
    "# Series of weights in kg\n",
    "weights = pd.Series({'Pete': 60, 'Mo': 80, 'Jay': 55, 'Claire': 70})\n",
    "\n",
    "example_dataframe = pd.DataFrame({'heights': heights, 'weights': weights})\n",
    "\n",
    "# In this notebook we can display a pandas dataframe in a\n",
    "# nice format without printing just by typing the dataframes\n",
    "# name.\n",
    "example_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also construct a `DataFrame` from a list of `dict`s like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series of heights in inches\n",
    "heights = {'Pete': 69, 'Mo': 72, 'Katy': 64, 'Alex': 80}\n",
    "# Series of weights in kg\n",
    "weights = {'Pete': 60, 'Mo': 80, 'Jay': 55, 'Claire': 70}\n",
    "\n",
    "example_dataframe = pd.DataFrame({'heights': heights, 'weights': weights})\n",
    "\n",
    "example_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can construct a `DataFrame` from a `numpy` array and label the columns using the `columns` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataframe = pd.DataFrame(\n",
    "    np.random.randint(60,80, size=(2, 3)),\n",
    "    columns=['heights', 'weights', 'favourite number'],\n",
    "    index=['Joe', 'Catelyn'])\n",
    "\n",
    "example_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the indices from a `Series` or `DataFrame` easily using the `index` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_series.index)\n",
    "print(example_dataframe.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also receieve the column headers from a `DataFrame` using the `columns` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_dataframe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` datatypes are incredibly useful and efficient when dealing with heterogeneous data. In this section we will give a, by no means comprehenive, selection of useful functions that `pandas` offers. We will use the below `DataFrame` in the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset = pd.DataFrame.from_dict({\n",
    "                    'eyelash_length': np.random.rand(50),\n",
    "                    'subject_ID': np.arange(50),\n",
    "                    'birth_year': np.random.randint(1980, 1990, size=50),\n",
    "                    'group': list('aabcdeacbeabcabcdeeedcdaebcaeddeacbeabcaddabbcecdb'),\n",
    "                    'sex': list('MMMFMFFMFFMMMFMFFMFFMFMFFMFMMFFFMFFFMFMMFMMFFFMFMF')\n",
    "})\n",
    "\n",
    "# Add in some missing data\n",
    "rows = np.random.randint(0,50,size=10)\n",
    "cols = np.random.randint(0,5,size=10)\n",
    "for i in range(10):\n",
    "    example_dataset.iloc[rows[i],cols[i]]= np.nan\n",
    "\n",
    "# Show our dataset\n",
    "example_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Boolean indexing to return subsets of the data. What is particularly nice is that in `Pandas` boolean logic is much easier to interpret, due to the use of column names. For example, hopefully the below line of code should be fairly intuitive;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset[(example_dataset['sex']=='M') & \n",
    "                (example_dataset['birth_year']>1987)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Note:** When using multiple boolean statements always use `()` brackets to make your logic clearer and less susceptible to coding errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This above is useful but the notation is a bit clunky - we had to type `example_dataset` four times to do this operation. We can do this a lot more easily with the `query` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform the same operation as in the above section with much cleaner syntax using the `query` method like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset.query('(sex == \"M\") & (birth_year > 1987)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Warning:** The `query` function may have problems with column names which can't be used as python identifiers (for example column names including a space). This is a common cause of `SyntaxError`'s for users new to `Pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing `NaN`s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When selecting data we may wish to first remove `NaN` values/missing data which could interfere with our logic. We can locate and remove all rows with `NaN` values in a specified column by using the `isna` function like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all subjects for whom we didn't record sex\n",
    "example_dataset[~example_dataset.sex.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is actually a method that lets us do this more in a more neat fashion; the `dropna` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all subjects with missing sex and birthyear information\n",
    "example_dataset.dropna(subset=['birth_year', 'sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sorting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we may wish to do when first looking at data is sort it by a variable we are interested in. Sorting can be done in `pandas` using the `sort_values` method. For example;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_example = example_dataset.sort_values('birth_year')\n",
    "sorted_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to get a row of the new sorted array, we can use the `iloc` function to index it like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_example.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Note:** We can still select the index `0` of the array under it's original ordering using `loc`. It can be very easy to confuse the `loc` and `iloc` methods. It is always worth checking you are using the correct method here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_example.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing by column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another great strength of the `pandas` package is that, much like `numpy`, it contains several methods for getting summary measures of columns of data. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "example_dataset.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation\n",
    "example_dataset.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of non-missing/non-NaN values\n",
    "example_dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One function which is useful as a sanity check whenever you are working in `pandas` is the `describe` method, which gives several common summary statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset.describe()\n",
    "\n",
    "# (The percentages in this table are quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use our own custom functions to apply to the columns of a `DataFrame` using the `apply` method. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a T statistic for the t-test that\n",
    "# the mean=1984\n",
    "#\n",
    "# i.e. T = (mean-1984)/(std/sqrt(n))\n",
    "def tstat1984(series):\n",
    "    \n",
    "    # Get T statistic\n",
    "    tStat = (series.mean()-1985)/(series.std()/np.sqrt(series.count()))\n",
    "    \n",
    "    return(tStat)\n",
    "\n",
    "# Return the T statistics... they should all be large as the mean\n",
    "# was not zero in any of our examples\n",
    "example_dataset.select_dtypes(np.number).apply(tstat1984)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Warning:** When applying custom functions to a `DataFrame` you must ensure you specify which datatypes you want to apply your function to. In the above we specified that we wanted to apply our function to any column containing entries that are `np.number` objects (i.e. `np.int64`, `np.float32`, etc...) using the `select_dtypes` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `apply` method actually allows us to apply several functions at once. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset.select_dtypes(np.number).apply([tstat1984, \n",
    "                                                'mean', \n",
    "                                                np.prod])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing by groupings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One extremely useful tool is the `groupby` tool which groups the data based on categorical variables of the users choosing. This returns an object, which we can iterate through like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sex, table_for_category in example_dataset.groupby('sex'):\n",
    "    \n",
    "    print(f'Mean age for sex {sex}: {row.birth_year.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more common application of the `groupby` method, however, is combining it with the `apply` function to get summary measures for groups. This is an extremely powerful functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset.groupby('group').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take the intersection of multiple categories like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset.groupby(['sex','group']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Note:** If one of the entries in the above is `NaN` then there were no subjects of that sex in that group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even do multiple groupings and multiple summary statistics at the same time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean and median for each (sex, group) combination \n",
    "example_dataset.groupby(['sex','group']).aggregate((np.median, np.mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also want to stratify based on a continuous variable. We can do this easily using the `cut` function like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the years into groups and take their means\n",
    "example_dataset.groupby(\n",
    "    pd.cut(example_dataset.birth_year, \n",
    "           bins=(1979, 1983, 1986, 1990))).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we were interested in the mean `eyelash_length` of every `group` for each `birth_year`. We could do the following;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset.groupby(['birth_year','group']).eyelash_length.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we have 10 `birth_year`s and 5 `group`s. This leaves us with potentially up to 50 lines in the above table. In this example, we probably wouldn't worry too much but on real data this could result in us getting very large tables very quickly!\n",
    "\n",
    "One way around this is to use the `unstack` method, which moves one of the groupings in the rows into the columns like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset.groupby(\n",
    "                ['birth_year','group']\n",
    "            ).eyelash_length.mean().unstack('group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shorter table is often referred to as \"wide form\" whilst the taller is referred to as \"long form\". \n",
    "\n",
    "There are many reasons you may want to work with both forms of data. for example, it often more convenient to group data using long form tables but often easier to generate plots with wide form tables. Often, it is also a question of personal preference.\n",
    "\n",
    "You can convert wide form back to long form using the `stack` method like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstack the dataframe\n",
    "unstacked = example_dataset.groupby(\n",
    "                ['birth_year','group']\n",
    "            ).eyelash_length.mean().unstack('group')\n",
    "\n",
    "# Stack the dataframe\n",
    "stacked = unstacked.stack('group')\n",
    "\n",
    "stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several alternatives to `stack` and `unstack`, such as  `pivot_table` and `melt`.\n",
    "\n",
    "`pivot_table` is particularly useful as, not only does it unstack the table, but it also handles grouping at the same time. For example, we could perform the same unstacking operation we did early with `pivot_table` like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked = example_dataset.pivot_table('eyelash_length', \n",
    "                                      'birth_year', \n",
    "                                      'group')\n",
    "stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can unstack the table we just made with the `melt` method. This is a little more fiddly, however, as the previous example, using `pivot_table` has changed the `birth_year` variable from a column in the table to the row index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change `birth_year` back to a column\n",
    "stacked['birth_year'] = stacked.index\n",
    "\n",
    "# Unstack our table\n",
    "unstacked = pd.melt(stacked, id_vars=['birth_year'], value_vars=['a','b','c','d','e'],\n",
    "         var_name='group', value_name='eyelash_length')\n",
    "\n",
    "# Our table will not be in the original order but we can sort that\n",
    "# After sorting the indices will be out of order so we reset those.\n",
    "unstacked.sort_values(['birth_year', 'group']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Note:** Our table is now longer. This is because we have included `NaN`/missing values we didn't include in our original table. We could remove these easily though, for example, with the `dropna` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading/Writing files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final footnote on `pandas` we will mention is that it is extremely fast at reading and writing files.\n",
    "\n",
    "`pandas` provides a wide range of tools for loading from text files, binary files, and SQL databases. The most commonly used function for this is the `pandas.read_{format}` function. For example, to read `csv` files we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_from_csv = pd.read_csv('05_pandas/example_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write to a csv using the `pandas.to_csv`  like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(np.random.randn(1000,1000))\n",
    "\n",
    "X.to_csv('05_pandas/example_data_we_made.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the fastest file reading tools in Python and worth knowing about! For example, compare the time `pandas` took to read the example `csv` to the time `numpy` takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Let's time pandas\n",
    "t1 = time.time()\n",
    "array_from_csv = pd.read_csv('05_pandas/example_data.csv').values\n",
    "t2 = time.time()\n",
    "print('pandas took ', t2-t1, ' seconds to read the csv file.')\n",
    "\n",
    "# Now time numpy\n",
    "t1 = time.time()\n",
    "array_from_csv = np.loadtxt('05_pandas/example_data.csv', delimiter=',')\n",
    "t2 = time.time()\n",
    "print('numpy took ', t2-t1, ' seconds to read the csv file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` is an extremely powerful tool. We have barely scratched the surface on it's capabilities here. To learn more, please see the official [`pandas` documentation here](https://pandas.pydata.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Read in the file `exercise_dataset.csv` as a pandas DataFrame. We are not interested in the `subject_id` and `age` variables so remove these from the DataFrame. *Hint: The [`drop`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) function may be useful for this*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** After collecting this data, you have found out that some, an extremely small minority in fact, of the subjects thought it would be funny to deliberately fill out the `favourite_animal` field in your survey with an object that is not an animal! Fearing these subjects may have filled out other values incorrectly, you wish to remove them from the DataFrame immediately.\n",
    "\n",
    "Investigate the `.value_counts()` function in the [`Pandas` documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html). What does this function do? Use the function to find the rows of the DataFrame with non-animal responses in the `favourite_animal` column and remove the rows from the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Your research is interested in the relationship between the size of the big toe on the left foot of each subject (`size_of_left_toe`) and the subjects heartrates (`heartrate`). Because of this, you have decided that you don't want to include any subjects which have any `NaN` values in either the `size_of_left_toe` or `heartrate` columns.\n",
    "\n",
    "Remove all rows of the DataFrame which include `NaN` values in either the `size_of_left_toe` or `heartrate` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Write a function which takes in a numpy array and a percentage $k$ and returns the k% quantile of the array. Now apply it to the columns of your DataFrame. Check your results against the inbuilt pandas `quantile` function. *Note: You do not have to worry about interpolating values and you can use the `numpy sort` attribute for this question. However, **no other numpy functions** should be used!*\n",
    "\n",
    "\n",
    "Use boolean indexing, and either your own function or the `quantile` function, to return a DataFrame containing only the subjects who were in the top 5\\% quantile for `heartrate` and the bottom 5\\% quantile for `size_of_left_toe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** The range of the `age` column in the DataFrame is from 10 to 59 years old. Perform the following operations on the DataFrame;\n",
    "\n",
    " - Use the `cut` function to seperate subjects into 5 age groups, each of ten years in length. \n",
    "\n",
    " - For each age range, obtain the mean `size_of_left_toe` and mean `heartrate` for both male (`M`) and female (`F`) subjects. Save a Dataframe containing these values as `mean_age_sex`. *Hint: Consider using the `groupby` function.*\n",
    "\n",
    " - For each age range, obtain the mean `size_of_left_toe` and `heartrate` for each of the groups listed in the `group` column (i.e. `a`, `b`, `c`, `d` and `e`). Save this in your workspace as `mean_age_group`. \n",
    "\n",
    " - Stack `mean_age_sex` and `mean_age_group` on top of one another using the [`concat` function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html). \n",
    " \n",
    "\n",
    "In practice, this is probably not a good way to lay out this data. List some reasons why you may not wish to lay out the data in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
